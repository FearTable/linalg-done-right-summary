\section{Invertibility and Isomorphisms}

\subsection{Invertible Linear Maps}
  \setcounter{thm}{58}
  %\textbf{3.59}
  \begin{mydef}
    $S\in \lvw$ with $ST=I_V \myand TW = I_W$ is called the ``inverse" (map?) of the invertible linear map $T \in \lvw$
  \end{mydef}

  %\textbf{3.60}
  \begin{thm}
    An invertible  linear map has a unique inverse.
  \end{thm}
  \begin{proof}
    Suppose $T\in \lvw$ is invertible and $S_1$ and $S_2$ are inverses of $T$. $\implies S_1 = S_1 I = S_1 (T S_2) = (S_1 T) S_2 = I S_2 = S_2 \implies S_1 = S_2$
  \end{proof}

  %\textbf{3.61}
  \begin{thm}
    The inverse is denoted by $T^{-1}$. $T^{-1}T=I_V$ and $T T^{-1} = I_W$ (?)
  \end{thm}

  %\setcounter{thm}{62}
  %\textbf{3.63}
  \begin{thm}
    Invertibility of a linear map $\in \lvw$ $\iff$ injectivity and surjectivity.
  \end{thm}

  \setcounter{thm}{64}
  %\textbf{3.65}
  \begin{thm}
    \label{injectivity-is-equivalent-to-surjectivity}
    If $\dim V = \dim W \neq \infty$, injectivity is equivalent to surjectivity for $T\in \linmap(V,W):$

    $T$ is invertible $\iff$ $T$ is injective $\iff$ $T$ is surjective.
  \end{thm}
  \begin{proof}
    The rank-nullity theorem (\ref{rank-nullity-theorem}) or fundamental theorem of linear maps states that
    \begin{equation}
      \label{rank-nullity-nested-equation}
      \dim V = \dim \mynull T + \dim \myrange T
    \end{equation}

    If $T$ is injective, $\dim \mynull T = 0$ and therefore $\dim \myrange T = \dim V = \dim W$, which means $T$ is surjective ($\myrange T = \dim W$). This is because every linearly independent list of vectors of of length $\dim W$ is a basis by \ref{every-lid-list-of-length-dim-v-is -a-basis-of-v}.

    If $T$ is surjective, we have $\dim \myrange T = \dim W$ to begin with and therefore \ref{rank-nullity-nested-equation} becomes
    \begin{equation}
      \dim \mynull T = \dim V - \dim \myrange T = \dim V - \dim W = 0
    \end{equation}
    which makes $T$ also injective. Since injectivity and surjectivy together imply invertibility, this ends the proof.
  \end{proof}



  \setcounter{thm}{67}
  %\textbf{3.68}
  \begin{thm}
    $ST = I \Leftrightarrow TS=I$
  \end{thm}

  \subsection{Isomorphic Vector Spaces}

  %\textbf{3.69}
  \begin{thm}
    An isomorphism is an invertible linear map. Two vector spaces are called isomorphic if there is a isomorphism from one vector space to the other. $T:V\to W$
  \end{thm}

  %\textbf{3.70}
  \begin{thm}
    Two \fd vector spaces $U$, $V$ over $\mathbb{F}$ are isomorphic $\iff$ they have the same dimension. $\dim U = \dim V$
  \end{thm}

  %\textbf{3.71}
  \begin{thm}
    Suppose $\oneTillN{v}$ is a basis of $V$ and $\oneTillM{w}$ is a basis of $W$. Then $\mathcal{M}$ is an isomorphism between $\lvw$ and $\mathbb{F}^{m,n}$
  \end{thm}

  %\textbf{3.72}
  \begin{thm}
    Suppose $V,W$ are \fd. $\implies \lvw$ is \fd and
    \begin{equation}
      \dim \lvw = (\dim V)\cdot(dim W)
    \end{equation}
  \end{thm}

  \subsection{Linear Maps Thought of as Matrix Multiplication}

  \begin{mydef}
    Let $v \in V$ and $\onetillm{v}$ be a basis of $V$ such that $v=b_1v_1+\dots+b_mv_m$.
    \\
    We define
    $
    \mathcal{M}(v) :\equiv
    \left (
    \begin{matrix}
      b_1 \\ \vdots \\ b_m
    \end{matrix}
    \right )
    $. The vector depends on the basis, but it is not included in the notation.
  \end{mydef}

  Recall: $
  \mathcal{M} (T) :\equiv
  \begin{blockarray}{cccc}
    & v_1 \quad \cdots & v_k & \cdots \quad v_n \\
    \begin{block}{c(ccc)}
      w_1    & & A_{1,k} & \\
      \vdots & & \vdots & \\
      w_m    & & A_{m,k} & \\
    \end{block}
  \end{blockarray}
  $


  \setcounter{thm}{74}
  %\textbf{3.75}
  \begin{thm}
    $\mathcal{M}_{\mathsmaller{\bullet}, k} = M(T v_k)$. The $k^{\text{th}}$ column of $\mathcal{M}(T)$ equals $(A_{1,k}, \dots, A_{m,k})^\top$
  \end{thm}

  %\textbf{3.76}
  \begin{thm}
    Linear maps act like matrix multiplication: Suppose $T\in \lvw$ and $v\in V$. Suppose $\onetilln{v}$ is a basis of $V$ and $\onetillm{w}$ is a basis of $W$. Then
    \begin{equation}
      \mathcal{M} (Tv)=\mathcal{M}(T) \cdot \mathcal{M}(v)
    \end{equation}

    Or using different notation:
    \begin{equation}
      \mathcal{M} (Tv, (\onetilln{v}), (\onetillm{w}))=\mathcal{M}(T, (\onetilln{v}), (\onetillm{w})) \cdot \mathcal{M}(v)
    \end{equation}

  \end{thm}

  \setcounter{thm}{77}
  %\textbf{3.78}
  \begin{thm}
    For $T \in \lvw: \dim \myrange T = \text{column rank of } \mathcal{M} (T)$
  \end{thm}

  \subsection{Change of basis}

  \begin{mydef-non}
    $\mathcal{M}(T, (\onetilln{v})) :\equiv \mathcal{M}(T, (\onetilln{v}),(\onetilln{v}))$
  \end{mydef-non}

  \setcounter{thm}{79}
  %\textbf{3.80}
  \begin{thm}
    A square matrix $A$ is called invertible, if there is some square matrix B of the same size such that $AB=BA=I$. We call $B$ the inverse of $A$ denoted by $A^{-1} :\equiv B$. Rules:
    \begin{itemize}
      \item $(A^{-1})^{-1}=A$
      \item $(AC)^{-1} = C^{-1}A^{-1}$ (Because $(AC)(C^{-1}A^{-1})=I$ and $(C^{-1}A^{-1})(AC)=I$)
    \end{itemize}
  \end{thm}

  %\textbf{3.81}
  \begin{thm}
    \bfemph{Matrix of product of linear maps:} \\
    Suppose $T\in \mathcal{L}(U,V)$ and $S\in \lvw$. If $\onetillm{u}$ is a basis of $U$, $\onetilln{v}$, is a basis of $V$ and $\onetill{w}{p}$ is a basis of $W$. Note that $\dim U = m$, $\dim V = n$, $\dim W = p$. Then we have:
    \begin{equation}
    \begin{gathered}
      \mmatrix(ST, (\onetillm{u}), (\onetill{w}{p})) = \\
      \mmatrix(S, (\onetilln{v}), (\onetill{w}{p} ))
      \cdot
      \mmatrix(T, (\onetillm{u}), (\onetilln{v}   ))
    \end{gathered}
    \end{equation}
    Or using different notation:
    \begin{equation}
      \mathcal{M}(ST) = \mathcal{M}(S) \cdot \mathcal{M}(T)
    \end{equation}
  \end{thm}

  \setcounter{thm}{83}
  %\textbf{3.84}
  \begin{thm}
    \bfemph{Change-of-basis formula:}\\
    Suppose $T \in \linmap(V)$. Let
    $V = \myspan{\onetillm{u}} = \myspan{\onetillm{v}}$ such that the $u$'s and $v$'s both form a basis. Let $A=\mmatrix(T, (\onetillm{u}))$ and $B=\mmatrix(T,(\onetillm{v}))$. Let
    $C=\mmatrix(I, \onetillm{u}, \onetillm{v})$. Then
    \begin {equation}
    A = C^{-1} B C
    \end {equation}
  \end{thm}

  \setcounter{thm}{85}
  %\textbf{3.86}
  \begin{thm}
    If $\onetillm{v}$ is a basis $V$ and $T\in \mathcal{L}$ is invertible, then
    \begin{equation}
      \begin{aligned}
        \mmatrix(T^{-1}) & = (\mmatrix(T))^{-1} \; \text{or} \\
        \mmatrix(T^{-1}, (\onetillm{v})) & =\mmatrix(T, (\onetillm{v}))^{-1}
      \end{aligned}
    \end{equation}
  \end{thm}
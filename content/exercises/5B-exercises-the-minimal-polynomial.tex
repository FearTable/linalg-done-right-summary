\section*{Exercises about the Minimal Polynomial}

\begin{xrcs}
  Suppose $T \in \linmap(V)$. Prove that $9$ is an eigenvalue of $T^2$ $\iff$ $3$ or $-3$ is an eigenvalue of $T$.
  \begin{xprf}
    \Leftarrowdirection Suppose $-3$ is an eigenvalue of $T$. Thus, there exists $v \in V$ such that $Tv = -3v$. If we apply $T$ a second time, we get $TT v = T (-3v) = -3 T v = (-3) (-3) v = 9v$. Therefore, $9$ is an eigenvalue of $T^2$. The case where we start with $3$ as an eigenvalue of $T$ is completely analogous.

    \Rightarrowdirection Let $v \in V$ be an eigenvector of $T^2$ corresponding to $\lambda = 9$. Thus, $T^2 v = \lambda v$ or equivalently, $T(Tv) = \lambda v$. Since eigenvectors are scalar mutiples of each other, we assume that $v$ is also an eigenvector of $T$. Hence, let $\alpha \in \myF$ be such that $Tv = \alpha v$. Therefore,
    \begin{align}
      T(Tv) &= \lambda v \\
      T(\alpha v) &= \lambda v \\
      \alpha T v &= \lambda v \\
      \alpha^2 v &= \lambda v = 9v
    \end{align}

    For this to happen, $\alpha$ must be $3$ or $-3$.
  \end{xprf}
\end{xrcs}

\exercise{3}
\begin{xrcs}
  Suppose $n \in \nat_{>0}$ and $T \in \linmap(\myF^n)$ is defined by $T(x_1 , \ddd, x_n) := (x_1 + \cdots + x_n, \ddd, x_1 + \cdots + x_n)$. The matrix $\mmatrix (T)$ of $T$ looks like this
  \begin{equation}
    \mmatrix (T) =
    \begin{pmatrix}
      1 & 1 & \cdots & 1 \\
      1 & 1 & \cdots & 1 \\
      \vdots & \vdots & \ddots & \vdots \\
      1 & 1 & \cdots & 1
    \end{pmatrix}
    %    =
    %    \begin{blockarray}{ccccc}
      %      \begin{block}{(ccccc)}
        %        1      & 1      & \dots   & 1      & 1 \\
        %        1      & 1      & \dots   & 1      & 1 \\
        %        \vdots & \vdots & \ddots  & \vdots & \vdots \\
        %        1      & 1      & \dots   & 1      & 1 \\
        %      \end{block}
      %    \end{blockarray}.
  \end{equation}

  \begin{enumerate}
    \item Find all eigenvalues and eigenvectors of $T$.
    \item Find the minimal polynomial of $T$.
  \end{enumerate}

  \begin{xsol}
    We want to find all $x \in V$ such that $Tx = \lambda x$. Therefore,
    \begin{equation}
      \begin{aligned}
        x_1 + \cdots + x_n &= \lambda x_1 \\
        & \; \; \vdots \\
        x_1 + \cdots + x_n &= \lambda x_n \\
      \end{aligned}
    \end{equation}

    If we define $S := x_1 + \cdots + x_n$, we can rewrite the system of equations as
    \begin{equation}
      \label{eq: equations for S}
      S= \lambda x_1, \ddd, S= \lambda x_n,
    \end{equation}

    or equivalently: $S = \lambda x_1 = \lambda x_2 = \cdots = \lambda x_n$. Solving by $x_i$ for $\lambda \neq 0$ gives
    \begin{equation}
      x_1 = \dfrac{S}{\lambda}, \; x_2 = \dfrac{S}{\lambda}, \; \ddd, \; x_n = \dfrac{S}{\lambda}
    \end{equation}

    Summing up all equations for $S$ in \eqref{eq: equations for S} gives:
    \begin{equation}
      nS = \lambda x_1 + \cdots + \lambda x_n = \lambda S
    \end{equation}

    Hence,
    \begin{equation}
      \begin{aligned}
        % &S=n \dfrac{S}{\lambda}\\
        &nS - \lambda S = 0 \\
        &S (n-\lambda) = 0. \quad \mytext{(which is the same as $(S-0)(n-\lambda) = 0$)}
      \end{aligned}
    \end{equation}

    If $\lambda = n$, then $x_1 = x_2 = \cdots = x_n$. Meaning all eigenvectors corresponding to the eigenvalue $n$ are s multiples of $(1, 1, \ddd ,1 ) \in \myF$.

    If $\lambda \neq n$, then $S ( \lambda - n) = 0$ implies that $S=0$ and thus, $\lambda = 0$. This means that $x$ belongs to the eigenspace of $0$, if $x_1 + x_2 + x_3 + \cdots + x_n = 0$.

    \prooffont{The minimal polynomial of T:}
    \begin{equation}
      \begin{aligned}
        T(e_1) &= e_1 + \cdots + e_n \\
        T(e_2) &= e_1 + \cdots + e_n \\
        & \; \; \vdots \\
        T(e_n) &= e_1 + \cdots + e_n
      \end{aligned}
    \end{equation}

    Define $v := e_1 + \cdots + e_n$. Note that $\myrange T = \myspan{v}$. Applying $T$ to $v$ gives
    \begin{equation}
      \begin{aligned}
        &T(v) = T(e_1 + \cdots + e_n) = T(e_1) + \cdots + T(e_n) = n v \\
        &T^2(v) = n T(v) % = n^2 v
      \end{aligned}
    \end{equation}

    The last line tells us that $T^2 = nT$ or equivalently $T(T-nI) = 0$. Therefore, the minimal polynomial is
    \begin{equation}
      p(z) = z(z-n).
    \end{equation}

    Because $\myrange T = \myspan{v}$, the polynomial is in fact minimal.
  \end{xsol}
\end{xrcs}

\exercise{4}
\begin{xrcs}
  Suppose $\myF = \compl$, $T \in \linmap(V)$, $p \in \polyn(\compl)$, and $\alpha \in \compl$. Prove that $\alpha$ is an eigenvalue of $p(T)$ $\iff$ $\alpha = p(\lambda)$ for some eigenvalue $\lambda$ of $T$.
  \begin{xprf}
    If $\lambda$ is an eigenvalue of $T$, then $\exists v \in V$ such that
    \begin{align}
      T v   &= \lambda   v \\
      T^2 v &= \lambda^2 v \\
      T^k v &= \lambda^k v \quad \forall k \in \nat_{>0}.
    \end{align}

    \Rightarrowdirection If $\alpha$ is an eigenvalue of $p(T)$, then $\exists u \in V$ such that
    \begin{align}
      \alpha u &= p(T)(u)  \\
      \alpha u &= c_0 u + c_1 T u + \cdots + c_{m-1} T^{m-1} u + T^m u \\
      \alpha u &= c_0 \lambda^0 u + c_1 \lambda^1 u + \cdots + c_{m-1} \lambda^{m-1} u + \lambda ^m u \\
      \alpha u &= (c_0 \lambda^0 + c_1 \lambda^1 + \cdots + c_{m-1} \lambda^{m-1} + \lambda ^m ) u \\
      \alpha   &= c_0 \lambda^0 + c_1 \lambda^1 + \cdots + c_{m-1} \lambda^{m-1} + \lambda ^m \\
      \alpha   &= p(\lambda)
    \end{align}

    But where have we been using the fact that $\myF = \compl$?
  \end{xprf}
\end{xrcs}

\exercise{12}
\begin{xrcs}
  Define $T \in \linmap(\myF^n)$ by $T(x_1, x_2, x_3, \ddd, x_n) = (x_1, 2 x_2, 3 x_3, \ddd,  n x_n)$. Find the minimal polynomial of $T$.

  \begin{xsol}
    For a standard basis $e_1, \ddd, e_n$ we have $T( e_1 + \cdots + e_n) = e_1 + 2e_2 + \cdots + n e_n$. Or equivalently:
    \begin{equation}
      \begin{aligned}
        T(e_1) &= e_1  \\
        T(e_2) &= 2e_2 \\
               &\; \vdots \\
        T(e_n) &= n e_n.
      \end{aligned}
    \end{equation}

    Hence, $e_1, \ddd, e_n$ are the $\dim \myF^n = n$ distinct eigenvectors with corresponding eigenvalues $1, 2,  \ddd, n$. This makes $Te_1, \ddd, Te_n$ linearly independent as well. Using \ref{thm: eigenvalues are the zeros of the minimal polynomial}, we conclude that the minimal polynomial of $T$ looks like this:
    \begin{equation}
      \label{eq: minmal polynomial of T(x_1, x_2, x_3, ..., x_n) = (x_1, 2 x_2, 3 x_3, ...,  n x_n)}
      p(z) = (z-1)(z-2)\cdots(z-n) \quad \forall z \in \myF^n.
    \end{equation}

    We can check if $\forall v \in \myF^n$, given as $v = a_1 e_1 + \cdots + a_n e_n$ ($a_i \in \myF$), the following equation holds:
    \begin{equation}
      (T-I)(T-2I)\cdots(T-nI)v=0.
    \end{equation}

    This is true because $a_k e_k \in \mynull (T-kI)$ for $k=1, \ddd, n$. Therefore,
    \begin{equation}
      \begin{aligned}
          (T-I)(T-2I)\cdots(T-nI)v & = (T-I)(T-2I)(T-3I)\cdots(T-nI)(a_1 e_1) \\
                                 & \quad + (T-I)(T-2I)(T-3I)\cdots(T-nI)(a_2 e_2) \\
                                 & \quad + (T-I)(T-2I)(T-3I)\cdots(T-nI)(a_3 e_3) \\
                                 & \quad + \; \cdots \\
                                 & \quad + (T-I)(T-2I)(T-3I)\cdots(T-nI)(a_n e_n) = 0.
      \end{aligned}
    \end{equation}

    Thus, we have found our minimal polynomial given in equation \eqref{eq: minmal polynomial of T(x_1, x_2, x_3, ..., x_n) = (x_1, 2 x_2, 3 x_3, ...,  n x_n)}. It is easy to conclude that there exists no polynomial of smaller degree that distributes to every basis vector of the sum $a_1 e_1 + \cdots + a_n e_n$.
  \end{xsol}
\end{xrcs}

\exercise{16}
\begin{xrcs}
  Suppose $a_0, a_1, \ddd, a_n \in \myF$. Let $T$ be the operator on $\myF$ whose matrix (with respect to the standard basis) is
  \begin{equation}
    \mmatrix (T) =
    \begin{blockarray}{cccccccc}
               & e_1 & e_2 & \cdots & & e_{n-1} & e_n      \\
      \begin{block}{c(ccccccc)}
        e_1    & 0   &     &        & &         & -a_0     \\
        e_2    & 1   & 0   &        & &         & -a_1     \\
        e_3    &     & 1   & \ddots & &         & -a_2     \\
        \vdots &     &     & \ddots & &         &  \vdots  \\
        e_{n-1}&     &     &        & & 0       & -a_{n-2} \\
        e_n    &     &     &        & & 1       & -a_{n-1} \\
      \end{block}
    \end{blockarray}.
  \end{equation}

  Note that all the other entries of this matrix are zero. Show that the minimal polynomial of $T$ is the polynomial
  \begin{equation}
    a_0 + a_1 z + \cdots + a_{n-1} z^{n-1} + z^n
  \end{equation}

  \begin{xsol}
    Looking at the matrix $\mmatrix(T)$ and having a glance at \ref{def: matrix of a linear map}, we observe that
    \begin{equation}
      \begin{aligned}
        T e_1 &= e_2 \\
        T e_2 &= e_3 = T(Te_1) = T^2 e_1 \\
        T e_3 &= e_4 = T(Te_2) = T^3 e_1 \\
        T e_4 &= e_5 = T(Te_3) = T^4 e_1 \\
              & \; \; \vdots \\
        T e_{n-1} &= e_n = T(Te_{n-2}) = T^{n-1}e_1 \\
        T e_n &= -a_0 e_1  -a_1 e_2 - a_2 e_3 - \cdots - a_{n-2} e_{n-1} - a_{n-1} e_n
               = T (T^{n-1} e_1) = T^n e_1.
      \end{aligned}
    \end{equation}

    We can rewrite the last expression as
    \begin{equation}
      -T^n (e_1) = a_0 e_1 + a_1 T e_1 + a_2 T^2 e_1 + \cdots + a_{n-2} T ^{n-2} e_1 + a_{n-1} T^{n-1} e_1
    \end{equation}

    The list $e_1, Te_1, T^2e_1, T^3e_1, \cdots, T^{n-1}e_1$, which equals the list $e_1, e_2, e_3, \cdots, e_{n-1}$, is linearly independent. Therefore, no other combination of the list equals $-T^5 e_1$. Hence, the minimal polynomial of $T$ is
    \begin{equation}
      a_0 + a_1 z + \cdots + a_{n-1}z^{n-1} + z^n.
    \end{equation}


  \end{xsol}
\end{xrcs}


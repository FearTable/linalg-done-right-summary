\section{Invariant Subspaces}

\subsection{Eigenvalues}

% 5.1
\begin{mydef} [operator]
  A \lm from a \vs to itself is called an ``operator''.
\end{mydef}

(Suppose $T\in \linmap(V)$, then may be $\left.T\right|_{V_{k}}$ is not an operator on a subspace $V_k$)

% 5.2
\begin{mydef} [invariant subspace]
  Let $T\in \linmap(V).$ $U \subseteq V$ is called ``invariant under $T$'' if $\forall u \in U: Tu \in U.$ \\
  Thus $U$ is invariant under $T$ if $\left.T\right|_{U}$ is an operator on $U.$
\end{mydef}

\begin{example}
  Let $T\in \linmap(\mathcal{P}(\mathbb{R}))$ such that $Tp=p'.$ Let $U=\mathcal{P}_4(\mathbb{R}) \subseteq \mathcal{P}(\mathbb{R}).$ Then $U$ is invariant under $T$
  because if $p \in U$, $\deg p = 4$ and $\deg (p')=3$.
\end{example}

\begin{example}
  Let $T\in \linmap(V)$. Then $\{0\}, V, \operatorname{null} T, \operatorname{range} T$ are all invariant. \\
  (Sometimes, $\operatorname{null} T = \{0\}$ and $\operatorname{range} T=V$ if $T$ is invertible.)
\end{example}

\bfemph{Invariant subspaces of dimension one: } 

Take any $v\in V, v\neq 0$ and let 
\begin{equation}
  U :\equiv \{  \lambda v \mid \lambda \in \myF \} = \myspan{v},
\end{equation}
then $U$ is a one\-/dimensional subspace of $V$. 

If $U$ is invariant under an operator $T \in \linmap (V)$, then $Tv  \in U$. $\implies \exists \lambda \in \myF: Tv = \lambda v$. \\
Conversely if $Tv = \lambda v$, $\lambda \in \myF$, then $\myspan{v}$ is a one-dimensional subspace of $V$ invariant under $T$.

% 5.5
\begin{mydef} [eigenvalue]
  Suppose $T\in \linmap (V)$. $\lambda \in \myF$ is called ``eigenvalue of $T$'' if there exists $v \in V$ such that $v \neq 0$ and $Tv = \lambda v$
\end{mydef}

% 5.7
\setcounter{thm}{6}
\begin{thm} [equivalent conditions to be an eigenvalue]
  \label{thm: equivalent conditions to be an eigenvalue}
  The following are equivalent for $T \in \linmap(V)$ and $\lambda \in \myF$:
  \begin{enumerate}[label=(\alph*)]
    \item $\lambda$ is an eigenvalue of $T$. \label{first}
    \item $T-\lambda I$ is not injective. \label{second}
    \item $T-\lambda I$ is not surjective. \label{third}
    \item $T-\lambda I$ is not invertible. \label{forth}
  \end{enumerate}
\end{thm}
\begin{prf}
  Conditions \ref{first} and \ref{second} are equivalent because the eigenvector $v$ is a solution to 
  \begin{equation}
    Tv=\lambda v
  \end{equation} which is equivalent to 
  \begin{equation}
    (T-\lambda I)v=0.
  \end{equation} So there is a non-zero solution to $T-\lambda I$.
  \ref{second}, \ref{third} and \ref{forth} are equivalent by \ref{injectivity-is-equivalent-to-surjectivity}.
\end{prf}

\setcounter{thm}{7}
\begin{mydef} [eigenvector]
  Let $T\in \linmap(V).$ A vector $v \in V$ is called an ``eigenvector'' of $T$ corresponding to $\lambda$ if $v\neq 0$ and $Tv = \lambda v$.
  In other words:
  \\A vector $v\in V, v \neq 0$ is an eigenvector corresponding to $\lambda \iff v \in \operatorname{null}(T-\lambda I_V)$
\end{mydef}

% 5.12
\setcounter{thm}{10}
\begin{thm}[linearly independent eigenvectors]
  \label{thm: linearly independent eigenvectors}
  Every list of eigenvectors of $T$ corresponding to distinct eigenvalues of $T$ is linearly independent.
\end{thm}
\begin{prf}
  Suppose the desired result is false. Then there exists a smallest list of length $m$ of linearly depen\-dent eigenvectors $v_1, \dots, v_m$ with eigenvalues $\lambda_1,$ $\dots$ $,\lambda_m$ of $T$. Since an eigenvector is unequal to the zero vector, $m$ must be $\geq 2$.
  
  Because of the minimality of $m$ and becaue our list is linearly dependent: 
  \begin{equation}
    \exists a_1, \dots, a_m \neq 0$ such that $a_1 v_1 + \cdots + a_m v_m = 0. 
  \end{equation}
  
  Now we apply $T-\lambda_m I$ on both sides of the equation and get
  \begin{equation}
    \begin{gathered}
      a_1 \lambda_1 v_1 - a_1 \lambda_m v_1
      + \cdots + \\
      a_{m-1} \lambda_{m-1} v_{m-1} - a_{m-1} \lambda_{m} v_{m-1} +
      \underbrace{a_m \lambda_m v_m -a_m \lambda_m v_m}_{=0} =0
    \end{gathered}
  \end{equation}
  
  Which is the same as:
  \begin{equation}
    a_1 \underbrace{(\lambda_1 - \lambda_m)}_{\neq 0} v_1 + \cdots + a_{m-1} \underbrace{(\lambda_{m-1}-\lambda_{m})}_{\neq 0} v_{m-1}=0
  \end{equation}
  
  Which contradicts the minimality of $m$. Therefore, no such linearly dependent list of eigenvectors can exist.
\end{prf}

\begin{thm}[number of eigenvectors]
  \label{thm: operator cannot have more eigenvalues than dimension of vector space}
  Each operator on $V$ has at most $\dim V$ distinct eigenvalues.
\end{thm}
\begin{prf}
  Let $T \in \linmap(V).$ Suppose $\lambda_1, \ldots, \lambda_m$ are distinct eigenvalues of with corresponding eigenvectors $v_1, \ldots, v_m \in V$. Then \ref{thm: linearly independent eigenvectors} implies that the list $v_1, \ldots, v_m$ is linearly independent. Thus \ref{thm: length of linearly dependent list less or equal to length of spanning list}
  implies $m \leq \dim V$.
\end{prf}


\subsection{Polynomials Applied to Operators}

% 5.13
\setcounter{thm}{12}
\begin{mydef} [notation $T^m$]
  Let $T \in \linmap(V)$ and $m\in \nat^{+}$
  \begin{itemize}
    \item $T^{m} :\equiv \underbrace{T \cdots T}_{\text{$m$ times}}$ or $T^{m} :\equiv T^{m-1} \cdot T$ such that $T^{m} \in \linmap(V)$
    \item $T^0 :\equiv I_V$
    \item If $T$ is invertible with inverse $T^{-1}$ then $T^{-m}\in \linmap(V)$ is defined by $T^{-m} :\equiv (T^{-1})^m$
  \end{itemize}
\end{mydef}
$\implies T^m T^n = T^{m+n}$ and $(T^m)^n=T^{mn}$ when $m,n \in \mathbb{Z}$ when $T$ is invertible. And $m,n \in \mathbb{N}$ if $T$ is not invertible.

\begin{mydef} [notation $p(T)$]
  For $\mathcal{P} (\myF) \ni p(z) = a_0+a_1z+a_2z^2+\cdots+a_mz^m$
 and
  $T \in \linmap (V)$ we define: 
  \begin{equation}
    p(T) :\equiv a_0 I + a_1 T + a_2 T^2 + \cdots a_m T^m.$ Note that $p(T) \in \linmap(V)
  \end{equation}
\end{mydef}

%TODO: example 5.15??

%TODO: example 5.16??

\setcounter{thm}{16}
\begin{thm} [multipliative properties]
  \label{multiplicative-properties}
  Suppose $p,q \in \mathcal{P} (\myF)$ and $T\in \linmap (V)$. Then \begin{equation}
    (p q)(T) = p(T) q(T) = q(T)p(T).
  \end{equation}
\end{thm}
\begin{prf} When a product of polynomials is expanded using the distributive property, it does not matter if the symbol is $z$ or $T$. Suppose $p(z) = \sum_{j=0}^{m} a_j z^j$ and $q(z)=\sum_{k=0}^{n} b_k z^k$ for all $z \in \myF$. Then  % wether?
  \begin{equation}
    (pq)(z) = \sum_{j=0}^{m} \sum_{k=0}^{n} a_j b_k z^{j+k} \myand
    (pq)(T) = \sum_{j=0}^{m} \sum_{k=0}^{n} a_j b_k T^{j+k}
    = \sum_{j=0}^{m} a_j T^j \sum_{k=0}^{n}  b_k T^k
  \end{equation}
  which is the same as $(pq)(T) = p(T)q(T)$ as well as $(pq)(T) = q(T)p(T)$
\end{prf}

\begin{thm} [null space and range of $p(T)$ are invariant under $T$]
  \label{thm: null space and range of p(T) are invariant under T}
  $T \in \linmap(V)$ and $p\in \mathcal{P} (\myF) \implies$
  $\operatorname{null} p(T)$ and $\operatorname{range} p(T)$ are invariant under $T$.
\end{thm}
\begin{prf}
  Suppose $u\in \operatorname{null} p(T)$
  \begin{equation}
    \implies p(T)u = 0. 
  \end{equation}
  
  Assoziativiy and distributivity of linear maps imply that 
  \begin{equation}
    (p(T))(Tu)=T(p(T)u)=T(0)=0.
  \end{equation}
  
  Which implies that
  \begin{equation}
    Tu \in \mynull p(T).
  \end{equation}
  
  Now suppose $u \in \myrange p(T)$
  \begin{equation}
    \begin{aligned}
      &\implies \exists v\in V: u=p(T)v \\
      &\implies Tu=T(p(T)v)=p(T)(Tv) \\
      &\implies Tu \in \myrange p(T)
    \end{aligned}
  \end{equation}
  \vspace{-1.1em}
\end{prf}
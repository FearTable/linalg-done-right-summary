\section{Span and Linear Independence}
\subsection{Linear Combinations and Span}

\setcounter{thm}{1}
\begin{mydef} [Linear combination]
  $a_1 v_1 + \cdots + a_m v_m$ is called a ``linear combination'' of a list of vectors $v_1, \dots, v_m$
\end{mydef}

\setcounter{thm}{3}
\begin{mydef} [Span of a list of vectors]
	The ``span" of a list of vectors $\onetillm{v}$ is defined as follows:
  \begin{equation}
    \begin{aligned}
      \myspan {v_1, \dots, v_m} &:\equiv \{a_1 v_1 + \cdots + a_m v_m \mid a_1, \dots a_m \in \mathbb{F} \}\\
      \myspan{ } &:\equiv \varnothing
    \end{aligned}
  \end{equation}
\end{mydef}

\setcounter{thm}{5}
%\textbf{2.6}
\begin{thm} [The span of a list of vectors is a subspace]
  The  span of a list of vectors in $V$ is the smallest subspace of $V$ containing all vectors in the list.
\end{thm}

%\textbf{2.7}
\begin{mydef} [Spanning a vector space]
  If $V=\myspan{\oneTillM{v}}$, we say $\oneTillM{v}$ ``spans'' $V$.
\end{mydef}

\setcounter{thm}{8}
%\textbf{2.9}
\begin{mydef} [Finite-dimensional vector space]
  Such a vector space is called finite\-/dimensional. We write $\dim V \neq \infty$ or $\dim V < \infty$
\end{mydef}

%\textbf{2.10, 2.11, 2.12}
\begin{mydef}
  The set of all polynomials is denoted by $\polyn (\myF) \subseteq \myF^\myF$.
\end{mydef}
\begin{mydef}
  $\polyn_m (\myF )=\myspan{1,z,\dots,z^m}$ denotes the set of all polynomials with coefficients in $\myF$ and degree at most $m$. The degree $m$ of a polynomial $p=a_0+a_1z+a_2z^2+\cdots+a_mz^m$ is denoted with $\degree p=m$.
  We also define for the zero polynomial $\degree 0 : \equiv -\infty$ \\
  (One should actually use the lambda notation $\lambda z.z^m$ to speak of functions)
\end{mydef}

\setcounter{thm}{12}
\begin{mydef}
  A vector space is called ``infinite\-/dimensional'' if it is not \fd. 
\end{mydef}


\subsection{Linear Independence}

\setcounter{thm}{14}
\begin{mydef} [Linear independence]
  There are $2$ ways to think about ``linear independence''. Lets first start with the motivation. A list of vectors $\oneTillM{v}$ is ``\lid'', if every combination of these vectors $w = b_1v_1 + \dots+ b_mv_m$ $\in \myspan{\oneTillM{v}}$ has a unique choice of scalars $b_1, \dots, b_m \in \myF$.

  \bfemph{The actual definition of linear independence:} \\
  A list of vectors $\oneTillM{v}$ is also called \lid, if the only way to combine them together and yield zero, is if we choose every coefficient $\lambda_i$ to be zero.
  \begin{equation}
    \lambda_1v_1 + \dots + \lambda_mv_m = 0 \iff \lambda_1 = \cdots = \lambda_m = 0
  \end{equation}

  Another way to put it:\\
  Let $w\in \myspan{v_1, \dots, v_m}$ sucht that for $a_1, \dots, a_m, c_1, \dots, c_m \in \myF$:
  \begin{equation}
    \begin{aligned}
      w & =a_1 v_1 + \cdots + a_m v_m \myand \\
      w & =c_1 v_1 + \cdots + c_m v_m \\
      & \iff \\
      0 & = \underbrace{(a_1 - c_1)}_{= \, 0\text{?}} v_1 + \cdots + \underbrace{(a_m -c_m)}_{= \, 0\text{?}} v_m
    \end{aligned}
  \end{equation}

  if $a_1 = c_1, a_2 = c_2, \, \dots \, , a_m = c_m$ is the only solution, the representation of $w$ as a linear combination of $v_1, \ldots, v_m$ is unique and the only way to add them up together equaling $0$ is $0v_1+\cdots+0v_m=0$. Both of these definitions are equivalent.

  The empty list $()$ is also defined to be linearly independent.
\end{mydef}




%\textbf{2.16}
\begin{mydef} [linear dependence]
  Otherwise, $\oneTillM{v}$ is called ``linearly dependent''.
\end{mydef}

%	\textbf{2.19} Linear dependence lemma:\\
%	Suppose $\oneTillM{v}\in V$ is a linearly dependent list.
%	$\implies \exists \kInOneTillM$ : $v_k \in \myspan{\oneTill{v}{k-1}}$


%\textbf{2.29}

\setcounter{thm}{18}
%\textbf{2.19}
\begin{thm} [linear dependence lemma]
  \label{thm: linear dependence lemma}
  Suppose $v_{1}, \dots, v_{m}\in V$ is a linearly dependent list.
  \begin{equation}
    \implies \exists k \in \{ 1, \dots, m \} : v_k \in \myspan {v_1, \dots, v_{k-1}}.
  \end{equation}
  Furthermore, if $k$ satisfies the conditions above and the $k^{\text{th}}$-term is removed from $v_1, \dots, v_m$, then the span of the remaining list equals $\myspan {v_1, \dots, v_{m}}$:
  \begin{equation}
    \myspan {v_1, \dots, v_{k-1}, v_{k+1}, \dots, v_m} = \myspan {v_1, \dots, v_m}
  \end{equation}
\end{thm}
\begin{prf}
  Because $\onetillm{v}$ are linearly dependent, we have 
  \begin{multline}
    a_1 v_1 + \cdots + a_m v_m = 0 \\
    $ where $a_1, \ldots, a_m \in \myF$ and $a_i \neq 0$ and $a_j \neq 0 $ for $i,j \in \{1 \cdots m\}
  \end{multline} 
  
  So we know, at least $2$ $a$'s are not $0$. 
  Let $k$ be the largest element of $\setonetillm$ such that $a_k \neq 0$. Then
  \begin{equation}
    v_k = - \frac{a_1}{a_n}v_1 - \cdots - \frac{a_{k-1}}{a_k}v_k,
  \end{equation}
  
  which proves that $v_k \in \myspan{v_1, \cdots, v_{k-1}}$.
  
  Now for the second claim, suppose $k$ is any element of $\setonetillm$ such that 
  \begin{equation}
    v_k \in \myspan{v_1, \cdots, v_{k-1}}.
  \end{equation}
  
  Then we have 
  \begin{equation}
    v_k = b_1v_1 + \cdots + b_{k-1}v_{k-1}, $ where $b_1, \cdots, b_{k-1} \in \myF.
    \label{eq: equation for v_k}
  \end{equation}
  
  Suppose $u \in \myspan{v_1, \ldots, v_m}.$ Then
  \begin{equation}
  u_k = c_1v_1 + \cdots + c_kv_k + \cdots +c_{m}u_{m} = , $ where $c_1, \cdots, c_{m} \in \myF.
  \end{equation}
  
  Of course, for $k=1$ or $k=2$ the equation looks different. Now we can replace $v_k$ with the right side of \ref{eq: equation for v_k}.
  \begin{equation}
    u = (c_1+b_1)v_1 + \cdots + (c_{k-1} + b_{k-1})v_{k-1} + c_{k+1} v_{k+1} + \cdots + c_m v_m
  \end{equation}
  
  Which shows $u \in \myspan {v_1, \dots, v_{k-1}, v_{k+1}, \dots, v_m} = \myspan {v_1, \dots, v_m}$
\end{prf}
\setcounter{thm}{21}

%\textbf{2.22}
\begin{thm}  [length of linearly independent list $\mathbb{\leq}$ length of spanning list]
  \label{thm: length of linearly dependent list less or equal to length of spanning list}
  In a \fd vector space, the length of every linearly independent list of vectors is less than or equal to the length of every spanning list of vectors.
\end{thm}
\begin{prf}
  Let $u_1, \ldots, u_m$ be a linearly independent list of vectors in $V$ and let $w_1, \ldots, w_n$ such that $V=\myspan{w_1, \ldots, w_n}$. We need to prove that $m \leq n$. We do this with following algorithm: 
  \begin{equation*}
      $Let $B_0 :\equiv  (w_1, \ldots, w_n)$. Note that $V=\myspan{B_0}.
  \end{equation*}
  
  \emph{\bfseries Step 1:} Let $B_1^* :\equiv (u_1, w_1, \ldots, w_n)$, which yields a linearly dependent list of length $n+1$, because $u_1$ can be written as a linear combination of $w_1, \ldots, w_n$. \\
  In other words, the list
  \begin{equation*}
    (u_1, w_1, \ldots, w_n) = B_1^* $ is linearly dependent.$
  \end{equation*}
  
  Thus by the linear dependence lemma (\ref{thm: linear dependence lemma}), one of the vectors of $B_1^*$ can be written as a linear combination of the of the previous vectors in the list. Since $u_1 \neq 0$, \ref{thm: linear dependence lemma} implies that we can remove one of the $w$'s, say $w_j$, so that the new list 
  \begin{equation*}
    B_1 :\equiv B_1^* - {w_j} = (u_1 w_1, \ldots, w_{j-1}, w_{j+1}, \ldots, w_n)
  \end{equation*}
  
  of length $n$ consisting of $u_1$ and the remaining $w$'s spans $V$. 
  \begin{equation*}
    V=\myspan{B_1}
  \end{equation*}
  
  \emph{\bfseries Step k, for k$=\mathbf{\mathsmaller{2}, \ldots,}$m:} The list $B_{k-1}$ of length $n$ from previous step $k-1$ spans $V$. So we have, $u_k \in \myspan{B_{k-1}}$, because the span never changed by our algorithm. If we add $u_k$ to the list, our list becomes linearly dependent. Let
  \begin{equation*}
    B_k^* :\equiv (u_1, \ldots, u_{k-1}, u_k, \underbrace{\widetilde w_{1}, \ldots, \widetilde w_{n-(k-1)})}_{\text{remaining $w$'s}} 
  \end{equation*}
  where $\widetilde w_{1}, \ldots, \widetilde w_{n-(k-1)}$ are our remaining $n-(k-1)$ $w$'s at our current step $k$, which are the same as from the previous list $B_{k-1}$$=$$(u_1, \ldots,u_{k-1},$$ \widetilde w_{1}, \ldots, \widetilde w_{n-(k-1)})$. Our new list has length $(n+1) = k + (n-(k-1))$. With the linear dependence lemma (\ref{thm: linear dependence lemma}), we can remove one vector of the list, since our new list $B_{k}^*$ was linearly dependent and spans $V$. 
  \begin{equation*}
    V=\myspan{B_{k}^*}. 
  \end{equation*}
  
  Because $u_1, \ldots, u_k$ are linearly independent, this vector can not be one of the $u's$. Hence there still must be at least one remaining $w$ at this step. $n-(k-1)$ $w's$ to be precise. So we can remove a $w$, lets say $\widetilde w_j$, so that the new list $B_k$ of length $n$ consisting of $u_1, \cdots, u_k$ and the remaining $w$'s spans $V$. 
  \begin{equation*}
    B_k = B_k^* - \widetilde w_j$ such that $ V=\myspan{B_k}$ and length $|B_k|=n
  \end{equation*}
  
  \emph{\bfseries Conclusion:} After step $m$, we have added all the $u's$ and the precess stops. At each step $k$, as we add a $u$ to $B_{k-1}$, the linear dependence lemma implies that there is some $w$ to remove from $B_{k}^*$. Thus there are at least as many $w$'s as $u's$.
  \begin{equation*}
    \implies m \leq n
  \end{equation*}
  $\implies$ the length of $u_1, \ldots, u_m$ $\leq$ the length of $w_1, \ldots, w_n$.
\end{prf}

\setcounter{thm}{24}
\begin{thm} [Finite-dimensional subspace]
  \label{thm: finite-dimensional subspace}
  Every subspace of a finite\-/dimensional vector space is finite\-/dimensional.
\end{thm}

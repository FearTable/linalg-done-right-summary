\section{The Minimal Polynomial}
\subsection{Existence of Eigenvalues on Complex Vector Spaces}

\begin{thm} [existence of eigenvalues]
  \label{thm: existence of eigenvalues}
  Every operator on a \fd non\-zero complex vector space has an eigenvalue.
\end{thm}
\begin{prf}
  Suppose $\infty>\dim(V)=n>0$ and $T\in \linmap(V).$ Choose $v\in V, v\neq0$. Then
  \begin{equation}
    v, Tv, T^2v, \dots, T^nv
  \end{equation}
  is not linearly independent,
  because the list has length $n+1$. Therefore some linear combination of these vectors equals $0$.

  $\implies$ there exists a non-constant polynomial $p$ of smallest degree such that
  \begin{equation}
    p(T)v = 0.
  \end{equation}

  By the first version of the fundamental theorem of algebra \ref{fundamental-theorem-of-algebra-first-version}, we have
  \begin{equation}
    \begin{aligned}
      &\exists \lambda \in \compl: p(\lambda) = 0. \\
      &\text{(\ref{factororing-out-zeros-of-a-polynomial-always-possible})}
      \implies \exists q \in \mathcal {P} (\compl): p(z) = (z-\lambda)  q(z) \quad \forall z \in \compl \\
      &\text{(\ref{multiplicative-properties})} \implies 0=p(T)v=(T-\lambda I) (q(T)v).
    \end{aligned}
  \end{equation}

  Because $q$ has a smaller degree than $p \implies q(T)v \neq 0$. (Why? May be because $q(T)v$ consists of $n=\dim V$ linearly independent vectors added together. The sum of zero is unique in this case.)

  $\implies$ $\lambda$ is an eigenvalue of $T$ with eigenvector $q(T)v$.
\end{prf}

\subsection{Eigenvalues and the Minimal Polynomial}


\begin{mydef} [monic polynomials]
  A \qt{monic polynomial} is a polynomial whose highest\-/degree coefficient equals $1$.
\end{mydef}
\begin{example}
  $p(z)=2+9z^2+z^7, \quad \deg p = 7$.
\end{example}

\begin{thm}[existence, uniqueness, and degree of minimal polynomial]
  \label{thm: unique monice polynomial of smallest degree}
  Suppose $T\in \linmap(V)$. Then there exists a unique monic polynomial $p\in \mathcal{P}(\myF)$ of smallest degree such that
  \begin{equation}
    p(T)=0.
  \end{equation}
  Furthermore $\deg p \leq \dim V$.
\end{thm}
\begin{prf} Before we can start our proof with induction, let us look at some base cases.

  If $\dim V=0$, then identity operator $I$ is the zero-operator on $V$ and we let $p=1$ such that
\begin{equation}
    1I\vec0=0.
\end{equation}

If $\dim V=1$, the list $v, Tv$ is linearly dependent for $v \in V, v\neq 0$ because it has length $2$ and we have $c_0v + Tv = 0$ for some $c_0 \in \myF$. If we choose $q(z) :\equiv c_0+z$ then
\begin{equation}
  q(T)v=(c_0 I+T)(v)=c_0v+Tv=0.
\end{equation}
So we have $\dim \mynull q(T) = 1$ and therefore $\dim \myrange q(T) = \dim V - \dim \myrange q(T) = 0$. So every vector on our one dimensional line is a multiple of $v$ and maps to zero if $q(T)$ is applied. So we have found our polynomial minimal $q(T)$.

  If $\dim V=2$, the list $v, Tv, T^2v$ is linearly dependent for $v\in V, v\neq0$ because it has length $3$. According to the linear dependence lemma \ref{thm: linear dependence lemma}, we either have
 \begin{equation}
     c_0v + Tv = 0 \mytext{or}
     c_0v + c_1Tv + T^2v = 0 \mytext{for some specific} c_0, c_1 \in  \myF.
 \end{equation}

  If we define $q(z) :\equiv c_0+z$ or $q(z) :\equiv c_0+c_1z+z^2$
%  $q(z) :\equiv c_0+\cdots c_mz^m$
%  accordingly for $m\in \{1,2\}$
  accordingly, then $q(T)v=0$ as before. Note that if $k \in \nat$, then
  \begin{equation}
    \label{eq: nice equation for q(t)}
    q(T)(T^kv)=T^k(q(T)v) =T^k (0) =0,
  \end{equation}

  which will be used later.

  In the first case where $(-1)c_0v=Tv$ and $q(z)=c_0+z$, the vector $v$ by itself is linearly independent and thus $\dim \mynull q(T) \geq 1$ and therefore
  \begin{equation}
    \dim \myrange q(T) \leq \dim V - \dim \mynull q(T) \leq 1.
  \end{equation}

  For a at most one\-/dimensioanl space like $\myrange q(T)$, we already now how to construct such a polynomial. Since $\myrange q(T)$ is invariant under $T$ by \ref{thm: null space and range of p(T) are invariant under T}, we can restrict $T$ to this subspace. So for the operator $\left. T \right |_{\myrange q(T)}$, we know how to construct such a polynomial. Let us call it $s$. Let $s$ be defined such that
  \begin{equation}
    \begin{aligned}
        &s (\left. T \right |_{\text{range $q(T)$}})=0, \mytext{which means that $s$ is the zero-operator of $\left. T \right |_{\myrange q(T)}.$}\\
        &\implies \forall u \in V: \left((sq)(T)\right)(u) = s(T)(q(T)u)=0.
    \end{aligned}
  \end{equation}
  Thus, $sq$ is a candidate to for our minimal polynomial of $T$.

  A similar reasoning goes for the case where $(-1)c_0v+(-1)c_1Tv=T^2v$ and $q(z) = c_0+c_1z+z^2.$
  Here we have $v$ and $Tv$ as linearly independent vectors. Equation \eqref{eq: nice equation for q(t)} tells us, that $v\in \mynull q(T)$ and $Tv \in \mynull q(T)$. Here we conclude that $\dim \mynull q(T) \geq 2$ and therefore $\dim \myrange q(T) = 0$.
%  Here we would multiply the identity operator $I$ with our polynomial $q(T)$ to get our wanted minimal polynomial. Another way to look at it: ^
  Since $\dim \mynull q(T) = 2$ we have that
  \begin{equation}
    \mynull q(T) = V.
  \end{equation}
  This means, every vector of $V$ gets maped to $0$ if $q(T)$ is applied. So we have found a minimal monic polynomial!

  As we can now see a pattern, we can use induction on $\dim V$ and we assume $\dim V > 0$ and that the theorem holds for all vector spaces of smaller dimension than $\dim V$.

  Let $v\in V, v \neq 0$. The list \begin{equation}
    v, Tv, \dots, T^{\dim V}
  \end{equation}
  has length $1+\dim V.$
  $\implies$ the list is linearly dependent.

  By the linear dependence lemma (\ref{thm: linear dependence lemma}), there is a smallest positive integer $m\leq \dim V$ such that
  \begin{equation}
    \begin{aligned}
      &c_0 v + c_1 Tv + \cdots + c_{m-1} T^{m-1} v + (1)\cdot T^m v = 0
      \mytext {for some} c_0, c_1, \ldots, c_{m-1} \in \myF. \mytext{ Let us define}\\
      &q(z) :\equiv c_0 + c_1z + \cdots + c_{m-1} z^{m-1} +z^{m} \in \mathcal{P}_m (\myF) \mytext{ accordingly.}
    \end{aligned}
  \end{equation}

  Thus we have
  \begin{equation}
    q(T) v=0. $ Note that $q(z)$ is a monic polynomial.$
  \end{equation}

  If $k \in \nat$, then
  \begin{equation}
    \label{eq: nice equation for q(T) again}
    q(T)(T^kv)=T^k(q(T)v) =T^k (0) =0.
  \end{equation}
  By the linear dependence lemma (\ref{thm: linear dependence lemma}) \begin{equation}
    \implies v, Tv, \dots, T^{m-1}v
  \end{equation}
  from before are linearly independent. Together with equation \eqref{eq: nice equation for q(T) again}
  \begin{equation}
    \begin{aligned}
      \implies &\dim \mynull q(T)   \geq m \\
      \implies &\dim \myrange q(T)  = \dim V - \dim \mynull q(T)
      \leq \dim V - m
    \end{aligned}
  \end{equation}

  Because $\myrange q(T)$ is invariant under $T$ by  \ref{thm: null space and range of p(T) are invariant under T}, we can apply our induction hypothesis to the operator $\left.T\right|_{\myrange q(T)}$.

  So there exists monic $s \in \mathcal{P} (\myF):$
  \begin{equation}
  \begin{aligned}
    &\deg s \leq \dim V - m \myand s(\left.T\right|_{\myrange q(T)})=0 \\
    &\implies \forall u \in V: \left((sq)(T)\right)(u) = s(T) (q(T)u) = 0,
  \end{aligned}
  \end{equation}

  because $q(T)u \in \myrange q(T)$ and \begin{equation}
    \left.s(T)\right|_{\myrange q(T)}=s\left( \left.T\right|_{\myrange q(T)} \right ).
  \end{equation}
  Therefore, $sq$ is a monic polynomial such that $\deg sq \leq \dim V$ and $(sq)(T)=0$.

  Proof of uniqueness: Let $p\in \mathcal{P} (\myF)$ a monic polynomial of smallest degree such that
  \begin{equation}
    p(T)=0.
  \end{equation} Let $r\in \mathcal{P} ( \myF)$ another monic polynomial of same degree such that $r(T)=0.$
  \begin{equation}
    \implies (p-r) (T) = 0
  \end{equation}

  and also $\deg (p-r) < \deg p = \deg r$ If $p-r \neq 0$, we could devide $p-r$ by the coefficient of the highest order term in $p-r$ to get a monic polynomial that when applied to $T$ gives the $0$-operator. This polynomial would have a smaller degree than $p$ or $r$, which would be a contradiction. Therefore $p-r=0 \iff p = r$.
\end{prf}

\setcounter{thm}{23}

\begin{mydef} [minimal polynomial]
  Let $T\in \linmap (v)$. The \qt{minimal polynomial of $T$} is the unique monic polynomial $p\in \mathcal{P}(\myF)$ of smallest degree s.t. $p(T)=0$
\end{mydef}
\bfemph{Computation:} Find the smallest $m \in \nat$ such that: \\
$c_0I + c_1 T + \cdots + c_{m-1} T^{m-1} = -T^{m}$ has a solution $c_0, \dots, c_{m-1} \in \myF$. Solve for $m=1,2,\dots,\dim V$

Even faster (usually), pick $v \in V$ with $v \neq 0$ and consider the equation
\begin{equation}
  c_0v + c_1Tv + \cdots + C_{\mydim V-1}T^{\mydim V-1}v=-T^{\mydim V}v.
\end{equation}
If this equation has a unique solution, as happens most of the time
\begin{equation}
  c_0, c_1, c_2, \dots, c_{\dim V-1}, 1
\end{equation}
are the coefficients of the minimal polynomial of $T$.
%TODO: do more.

\setcounter{thm}{26}
\begin{thm} [eigenvalues are the zeros of the minimal polynomial]
  \label{thm: eigenvalues are the zeros of the minimal polynomial}
  Let $T \in \linmap(V)$. Then
  \begin{enumerate}[label=(\alph*)]
    \item The zeros of the minimal polynomial of $T$ are the eigenvalues of $T$.
    \item If $V$ is a complex vector space, the minimal polynomial has the form
    \begin{equation}
      (z-\lambda_1)\cdots(z-\lambda_m), \mytext{where} \lambda_1, \dots, \lambda_m
    \end{equation} are the eigenvalues of $T$, possibly with repetitions.
  \end{enumerate}
\end{thm}
\begin{prf} Let $p$ be the minimal polynomial of $T$.
  \begin{enumerate}[label=(\alph*)]
    \item Suppose $\lambda \in \myF$ is a zero of $p$. $\implies p(z)=(z-\lambda)q(z)$, whre $q$ is a monic polynomial with coefficients in $\myF$ (see \ref{factororing-out-zeros-of-a-polynomial-always-possible})
    \begin{equation}
      p(T)=0\implies 0=(T-\lambda I)(q(T)v) \quad \forall v\in V.
    \end{equation}
    Because $q$ is of lesser degree than $p$, there exists at least one vector $v\in V$ sucht that $q(T)v \neq 0$, which makes $q(T)v$ an eigenvector with eigenvalue $\lambda$.

    Suppose $\lambda \in \myF$ is an eigenvalue of $T$. Thus there exists $v\in V, v \neq 0$ such that $Tv=\lambda v$. Repeated applications of $T$ on both sides of this equation show that $T^kv =\lambda^k v \quad \forall k\in \nat$.
    $\implies p(T)v=p(\lambda)v$. Because $p$ is the minimal polynomial of $T$, we have $p(T)v=0$. $\implies p(\lambda) = 0$. $\implies$ $\lambda$ is a zero of $p$.

    \item use (a) and the second version of the fundamental theorem of algebra. (\ref{fundamental-theorem-of-algebra-second-version})
  \end{enumerate}
  \vspace{-1.1em}
\end{prf}

\setcounter{thm}{28}
\begin{thm}[every \qt{zero-polynomial} is a multiple of the minimal polynomial]
  \label{thm: every zero polynomial is a multiple of the minimal polynomial}
  $T\in \linmap(V)$ and $q \in \mathcal{P} (\myF)$:
  \begin{equation}
    q(T)=0 \iff q \mytext{is a multiple of the minimal polynomial of} T.
  \end{equation}
\end{thm}
\begin{prf}
  Let $p$ denote the minimal polynomial of $T$.

  \begin{description}

    \item{\qt{$\Rightarrow$ direction:}}{
      Suppose $q(T)=0$.
      By (\ref{division-algorithm-for-polynomials}) there exists $s,r \in \mathcal{P} (\myF)$ such that
      \begin{equation}
        q=ps+r, \quad \deg r < \deg p
      \end{equation}
      We have
      \begin{equation}
        \label{aa}
        0 = q(T) = p(T)s(T) + r(T) = r(T).
      \end{equation}
      The equation above implies that $r=0$. Otherwise, dividing $r$ by its highest\-/degree coefficient would produce a monic polynomial that when applied to $T$ gives $0$. A contradiction because $\deg r < \deg p$ and $p$ is minimal. Thus \ref{aa} becomes the equation $q=ps$, as desired
    }
    \item{\qt{$\Leftarrow$ direction:}}{
      Suppose $q=ps$ for $q,p,s \in \mathcal{P}(\myF)$. We have
      \begin{equation}
        q(T) = p(T)s(T)=0s(T)=0,
      \end{equation}
      as desired. Which proves both directions.
    }
  \end{description}
   \vspace{-1.1em}
\end{prf}

\setcounter{thm}{30}
\begin{thm}[minimal polynomial of a restriction operator]
  \label{thm: minimal polynomial of a restriction operator}
  If $U$ is a subspace of $V$, then the minimal polynomial of $T$ is a polynomial multiple of the minimal polynomial of $\left .T \right | _{ U}$
\end{thm}
\begin{prf}
  Suppose $p$ is the minimal polynomial of $T$.
  \begin{equation}
    \implies p(T)v=0 \quad \forall v \in V.
  \end{equation}
  In particular,
  \begin{equation}
    p(T)u=0 \quad \forall u\in U.
  \end{equation} Thus $p\left( \left.T\right|_{U} \right)=0.$ Now the previous theorem
  \ref{thm: every zero polynomial is a multiple of the minimal polynomial} tells us, that $p$ is a polynomial multiple of the minimal polynomial of $\left. T \right |_U$.
\end{prf}

\begin{thm} [invertibility and the constant term of the minimal polynomial]
  Let $T \in \linmap (V)$. Then we have: $T$ is not invertible $\iff$ the constant term of the minimal polynomial of $T$ is $0$.
\end{thm}
\begin{prf}
  $T$ is not invertible $\iff_{\text{(\ref{thm: equivalent conditions to be an eigenvalue})}}$ $0$ is an eigenvalue of $T$ $\iff_{(\text{\ref{thm: eigenvalues are the zeros of the minimal polynomial})}}$ $0$ is a zero of $p$ $\mathsmaller{\iff}$ the constant term of $p$ is $0$.
  (In the first equivalence, we have actually used that $0$ is an eigenvalue of $T$ if and only if $T-0I$ is not invertible, according to \ref{thm: equivalent conditions to be an eigenvalue}.)
\end{prf}

\subsection{Eigenvalues on Odd-Dimensional Real Vector Spaces}
\begin{thm}[even-dimensional null space]
  Suppose $\myF = \real$ and $V$ is \fd.
  Suppose also that $T \in \linmap (V)$ and $b,c \in \real$ with $b^2 < 4c$.
  \begin{equation}
    \implies \dim \mynull (T^2 +bT +cI) \mytext{is an even number}
  \end{equation}
\end{thm}

\begin{thm}[operators on odd-dimensional vectors spaces have eigenvalues]
  Every operator on an odd\-/dimensional vector space has an eigenvalue.
\end{thm}
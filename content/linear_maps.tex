\chapter{Linear Maps}
\section{\vs of linear maps}
A \lm from $V$ to $W$ is a function $T:V\to W$ with following properties:
\begin{itemize}
	\item additivity: $T(u+v)=Tu + Tv \qquad \forall u,v \in V$
	\item homogenity: $T(\lambda v)=\lambda (Tv) \qquad 
	\forall \lambda \in \mathbb{F} \; \forall v\in V$
\end{itemize}
The set of all linear maps from $V$ to $W$ is denoted by $\mathcal{L}(V,W)$. For The set of all linear maps from $V$ to itself we use $\mathcal{L}(V) :\equiv \mathcal{L}(V,V)$

\textbf{Linear map lemma: }
Suppose $\onetilln{v}$ is a basis of $V$ and $\onetilln{w} \in W$, where the $w$'s do not necessarily form a basis. Then there exist a unique \lm $T:V\to W$ or $T \in \linmap(V,W)$ such that
\begin{itemize}
	\item[] $Tv_{k} = w_k \quad \forall \kinonetilln.$
\end{itemize}
It is of the form $T(c_1 v_1 + \cdots c_n v_n) \mapsto c_1 w_1 + \cdots + c_n w_n$

\setcounter{thm}{4}
\begin{mydef}
    The sum and the product of linear maps:\\
    If $S, T \in \lvw$, $v \in V$, $\lambda \in \mathbb{F} $:
    \begin{itemize}
    	\item $(S+T)(v) :\equiv Sv+Tv$
    	\item $(\lambda T)(v) : \equiv \lambda (Tv)$
    \end{itemize}
\end{mydef}

\setcounter{thm}{5}
%\textbf{3.6} 
\begin{thm}
    With these operations above, $\lvw$ is itself a \vs.
\end{thm}

\setcounter{thm}{6}
%\textbf{3.7} 
\begin{mydef}
    Let $T \in \lin{U}{V}$ and $S \in \lin{V}{W}$. We define the product $ST \in \lin{U}{W}$ as follows:
    \begin{itemize}
    	\item[] $(ST)(u) :\equiv S(Tu) \quad \forall u \in U$
    \end{itemize}
\end{mydef}

%\textbf{3.8} 
\begin{thm}
    With these definitions we have
    \begin{itemize}
    	\item \bfemph{Associativity:} $(T_1 T_2) T_3 = T_1 (T_2 T_3)$, whenever $T_3$ maps into the Domain of $T_2$ and $T_2$ maps into the Domain of $T_1$.
    	\item \bfemph{Identity:} $T I = I T = T$ for $T \in \lvw$ (The first $I$ is the identity operator on $V$ and the second $I$ the identity operator on $W$. We could also write $T I_V = I_W T$
    	\item \bfemph{Distributive properties:} For $T, T_1, T_2 \in \lin{U}{V}$ and $S, S_1, S_2 \in \lin{V}{W}$: \\ $(S_1 + S_2)T=S_1 T + S_2 T$ and $S(T_1 + T_2)=S T_1 + S T_2$
    	\item \bfemph{Non-commutative:} $ST \neq TS$ in general.
    \end{itemize}
\end{thm}

\setcounter{thm}{9}
\begin{thm}
     $T\in \lvw \implies T(0)=0$. Proof: $T(0) = T(0+0) = T(0) + T(0)$. Subtracting $T(0)$ on both sides ends the proof.
\end{thm}

\section{Null spaces, ranges and injectivity}
$\mynull T :\equiv \ker T :\equiv \{ v \in V \mid Tv=0\} \subseteq V$ for $T \in \lvw$

\setcounter{thm}{12}
%\textbf{3.13} 
\begin{thm}
    $\mynull T$ is a subspace of $V$
\end{thm}

\setcounter{thm}{13}
%\textbf{3.14} 
\begin{mydef}
    A function $T: V \to W$ is called injective if $Tu = Tv \implies u = v$. \\
Or analogous: $u \neq v \implies Tu \neq Tv$ 
\end{mydef}

\setcounter{thm}{14}
%\textbf{3.15} 
\begin{mydef}
    Let $T \in \lvw$. Then $T$ is injective $\iff \mynull T = \varnothing$
\end{mydef}

\section{Definition of Range}
\setcounter{thm}{15}
%\textbf{3.16} 
\begin{thm}
    $\operatorname{range}T= \{Tv \mid v \in V\} \subseteq W$ for $T \in \lvw$
\end{thm}

\setcounter{thm}{17}
%\textbf{3.18} 
\begin{thm}
    $T\in \lvw \implies \myrange T$ is a subspace of $W$.
\end{thm}

\setcounter{thm}{18}
%\textbf{3.19} 
\begin{thm}
    If $\myrange T=W$, $T$ is called ``surjektive".
\end{thm} 

\setcounter{thm}{20}
%\textbf{3.21} 
\begin{thm}
    Fundamental theorem of linear maps or \textbf{``rank nullity theorem":} \\
    For $T \in \lvw$:
    \begin{equation}
    	\dim V = 
    	\underbrace{ \dim \mynull T }_{\text{nullity}}
    	+ \underbrace{\dim \myrange T}_{\text{rank}}
    \end{equation}
\end{thm}

\setcounter{thm}{21}
%\textbf{3.22} 
\begin{thm}
    If $\dim V > \dim W \implies$ No \lm from $V$ to $W$ is injective. 
\end{thm}

\setcounter{thm}{23}
%\textbf{3.24} 
\begin{thm}
    If $\dim V < \dim W \implies$ No \lm from $V$ to $W$ is surjective.
\end{thm}

\setcounter{thm}{25}
%\textbf{3.26} 
\begin{thm}
    A homogeneous system of linear equations with more variables then equations has nonzero solutions.
\end{thm}

%\textbf{3.28} 
\setcounter{thm}{27}
\begin{thm}
	An inhomogeneous system of linear equations with more equations then variables has no solutions for some choice of constant terms.
\end{thm}

\section{Matrices}
\setcounter{thm}{40}
%\textbf{3.41} 

\begin{mydef}
    $(AB)_{j,k} :\equiv \sum_{r=1}^{m} A_{j,r} B_{r,k}$ for $A\in \myF^{m,n}$, $B\in \myF^{n,p}$, $AB \in \myF^{m,p}$
\end{mydef}

%\textbf{3.46} 
\setcounter{thm}{45}
\begin{thm}
    $(AB)_{j,k} = A_{j, \mathsmaller{\bullet}} B_{\mathsmaller{\bullet}, k}$ if $1 \leq j \leq m$ and $1 \leq k \leq p$
\end{thm}

%\textbf{3.31} 
\setcounter{thm}{30}
\begin{thm}
    Supp $T \in \lvw$ and let $\onetilln{v}$ be a basis of $V$ and $\onetillm{w}$ be a basis of $W$. The matrix of T with respect of these bases is the $m$-by-$n$ Matrix called $\mathcal{M}(T) :\equiv A$ whose entries $A_{j,k}$ are defined by
	\begin{equation}
		Tv_k :\equiv A_{1,k}w_1+\cdots+A_{m,k}w_m	
	\end{equation}
	also denoted as $\mathcal{M}(T,(\onetillm{v}), (\onetillm{w})).$
\end{thm}

\setcounter{thm}{49}
\begin{thm}
    Suppose $A \in \myF^{m,n}$ and $b=\left(\begin{matrix}b_1\\ \vdots \\ b_n \end{matrix}\right) \in \myF^{n,1}$. Then $Ab = b_1 A_{\mathsmaller{\bullet}, 1} + \dots + b_n A_{\mathsmaller{\bullet},n}$ 
\end{thm}

\section{Invertibility and Isomorphisms}

\subsection{Inverse}
\setcounter{thm}{58}
%\textbf{3.59} 
\begin{mydef}
    $S\in \lvw$ with $ST=I_V \wedge TW = I_W$ is called the ``inverse" (map?) of the invertible linear map $T \in \lvw$ 
\end{mydef}

%\textbf{3.60} 
\begin{thm}
    An invertible  linear map has a unique inverse. 
\end{thm}
\begin{proof}
    Suppose $T\in \lvw$ is invertible and $S_1$ and $S_2$ are inverses of $T$. $\implies S_1 = S_1 I = S_1 (T S_2) = (S_1 T) S_2 = I S_2 = S_2 \implies S_1 = S_2$ 
\end{proof}

%\textbf{3.61} 
\begin{thm}
    The inverse is denoted by $T^{-1}$. $T^{-1}T=I_V$ and $T T^{-1} = I_W$ (?)
\end{thm}

%\setcounter{thm}{62}
%\textbf{3.63} 
\begin{thm}
    Invertibility of a linear map $\in \lvw$ $\Leftrightarrow$ injectivity and surjectivity.
\end{thm}

\setcounter{thm}{64}
%\textbf{3.65} 
\begin{thm}
    Injectivity is equivalent to surjectivity (if $\dim V = \dim W < \infty$)
\end{thm}

\setcounter{thm}{67}
%\textbf{3.68} 
\begin{thm}
    $ST = I \Leftrightarrow TS=I$
\end{thm}

%\textbf{3.69} 
\begin{thm}
    An isomorphism is an invertible linear map. Two vector spaces are called isomorphic if there is a isomorphism from one vector space to the other. $T:V\to W$ 
\end{thm}

%\textbf{3.70} 
\begin{thm}
    Two \fd vector spaces $U$, $V$ over $\mathbb{F}$ are isomorphic $\iff$ they have the same dimension. $\dim U = \dim V$
\end{thm}

%\textbf{3.71} 
\begin{thm}
    Suppose $\oneTillN{v}$ is a basis of $V$ and $\oneTillM{w}$ is a basis of $W$. Then $\mathcal{M}$ is an isomorphism between $\lvw$ and $\mathbb{F}^{m,n}$ 
\end{thm}

%\textbf{3.72} 
\begin{thm}
    Suppose $V,W$ are \fd. $\implies \lvw$ is \fd and 
    \begin{equation}
    	\dim \lvw = (\dim V)\cdot(dim W)
    \end{equation}
\end{thm}

\section{Linear maps thought of as matrix multiplication}
Let $v \in V$, $V=\myspan{\onetillm{v}}$ and $v=b_1v_1+\dots+b_mv_m$. We define
\begin{equation}
	\mathcal{M}(v) :\equiv 
	\left (
	\begin{matrix} 
		b_1 \\ \vdots \\ b_m 
	\end{matrix}
	\right )
\end{equation}

\[
\mathcal{M} (T) :\equiv 
\begin{blockarray}{cccc}
	& v_1 \cdots & v_k & \cdots v_n \\
	\begin{block}{c(ccc)}
		w_1    & & A_{1,k} & \\
		\vdots & & \vdots & \\
		w_m    & & A_{m,k} & \\
	\end{block}
\end{blockarray}
\]

\setcounter{thm}{74}
%\textbf{3.75} 
$\mathcal{M}_{\mathsmaller{\bullet}, k} = M(T v_k)$. The $k^{\text{th}}$ column of $\mathcal{M}(T)$ equals $(A_{1,k}, \dots, A_{m,k})^\top$

\textbf{3.76} Linear maps act like matrix multiplication: Suppose $T\in \lvw$ and $v\in V$.
\begin{equation}
	\implies \mathcal{M} (Tv)=\mathcal{M}(T) \cdot \mathcal{M}(v)
\end{equation}

\setcounter{thm}{77}
\textbf{3.78} For $T \in \lvw: \dim \myrange T = \text{column rank of } \mathcal{M} (T)$

\section{Change of basis}
$\mathcal{M}(T, (\onetilln{v})) :\equiv \mathcal{M}(T, (\onetilln{v}),(\onetilln{v}))$

\setcounter{thm}{79}
\textbf{3.80} A square matrix $A$ is called invertible, if there is some square matrix B of the same size such that $AB=BA=I$. We call $B$ the inverse of $A$ denoted by $A^{-1} :\equiv B$. Rules: 
\begin{itemize}
	\item $(A^{-1})^{-1}=A$
	\item $(AC)^{-1} = C^{-1}A^{-1}$ (Because $(AC)(C^{-1}A^{-1})=I$ and $(C^{-1}A^{-1})(AC)=I$)
\end{itemize}

\textbf{3.81} matrix of product of linear maps \\
Suppose $T\in \mathcal{L}(U,V)$ and $S\in \lvw$. If $\onetillm{u}$ is a basis of $U$, $\onetilln{v}$, is a basis of $V$ and $\onetill{w}{p}$ is a basis of $W$. Note that $\dim U = m$, $\dim V = n$, $\dim W = p$. Then we have: 
\begin{multline}
	\mmatrix(ST, (\onetillm{u}), (\onetill{w}{p})) = \\
	\mmatrix(S, (\onetilln{v}), (\onetill{w}{p} )) \cdot
	\mmatrix(T, (\onetillm{u}), (\onetilln{v}   ))
\end{multline}

\setcounter{thm}{83}
\textbf{3.84} change-of-basis formula: Suppose $T \in \linmap(V)$. Let 
$V = \myspan{\onetillm{u}} = \myspan{\onetillm{v}}$ such that the u's and v's both form a basis. Let $A=\mmatrix(T, (\onetillm{u}))$ and $B=\mmatrix(T,(\onetillm{v}))$. Let  
$C=\mmatrix(I, \onetillm{u}, \onetillm{v})$ 
\begin {equation}
\implies A = C^{-1} B C
\end {equation} 

\setcounter{thm}{85}
\textbf{3.86} If $\onetillm{v}$ is a basis $V$ and $T\in \mathcal{L}$ is invertible, then 
\begin{equation}
	\begin{aligned}
		\mmatrix(T^{-1}) & = (\mmatrix(T))^{-1} \; \text{or} \\
		\mmatrix(T^{-1}, (\onetillm{v})) & =\mmatrix(T, (\onetillm{v}))^{-1}
	\end{aligned}
\end{equation}

\section{Products and quotients of vector spaces}
\begin{equation}
	\begin{aligned}
		v_1 \times \cdots \times v_m &:\equiv \{ (v_1, \dots, v_m) \mid v_1 \in V_1, \dots, v_m \in V_m\} \\
		(u_1, \dots, u_m) + (v_1, \dots, v_m) &:\equiv (u_1+v_1, \dots, u_m+v_m) \\
		\lambda (v_1, \dots, v_m) &:\equiv (\lambda v_1, \dots, \lambda v_m)			
	\end{aligned}
\end{equation}

\setcounter{thm}{88}
\textbf{3.89} $V_1 \times \cdots \times V_m$ is a vector space over $\mathbb{F}$.

\setcounter{thm}{91}
\textbf{3.92} $\dim (V_1 \times \cdots \times V_m) = \dim V_1 + \cdots + \dim V_m$

\textbf{3.93} Let $\Gamma: V_1 \times \cdots \times V_m \to V_1 + \cdots + V_m, \Gamma(v_1, \cdots, v_m) \mapsto v_1 + \cdots + v_m$ \\
Then $v_1 + \cdots + v_m$ is a direct sum $\iff$ $\Gamma$ is injective. 

\textbf{3.94} $V_1 + \cdots + V_1$ is a direct sum $\iff$
$\dim (V_1+\cdots+V_m) = \dim V_1 + \cdots + \dim V_m$

\section{Quotient spaces}
\textbf{3.95, 3.97} $v+U :\equiv \{v+U \mid u\in U\}$ for $v\in V$ and $U\subseteq V$ is said to be ``a translate" of $U$.

\setcounter{thm}{98}
\textbf{3.99} $V/U :\equiv \{v+U \mid v\in V\}$ is called ``quotient space".\\
example $1$: If $U=\{ (x,2x)\in \mathbb{R}^2 \mid x\in \mathbb{R} \} \implies \mathbb{R}/U$ is the set of all lines with slope $2$.  \\
example $2$: If $U$ is a plane in $\mathbb{R}^3$ $\implies$ $\mathbb{R}^3/U$ is the set of all planes parallel to $U$.

\setcounter{thm}{100}
\textbf{3.101} $ U \subseteq V$ and $v,w\in V$. Then
$$v-w \in U \iff v+U = w + U \iff (v+U) \cap (w+U) \neq \varnothing$$
That means, two translates of a subspaces are equal or disjoint.

\textbf{3.102} Definition of addition and scalar multiplication on $V/U$.
\begin{equation}
	\begin{aligned}
		(v+U)+(w+U) & :\equiv (v+w) + U \\
		\lambda (v+U) & :\equiv (\lambda v) + U \qquad \forall v,w \in V \text{ and } \forall \lambda \in \mathbb{F} 
		\text{ and } U \subseteq V
	\end{aligned}
\end{equation} 
\textbf{3.103} $V/U$ is a vector space. \\
additive identity: $0+u = u$. \\
additive inverse: $(-v)+U$.

\textbf{3.104} TODO \textbf{3.105} TODO

\section{Duality, dual space and dual map}
\textbf{3.108} A ``linear functional" is an element of $\mathcal{L}(V, \mathbb{F})$\\
\textbf{Examples:} 
\begin{equation} 
	\begin{array}{lll}
		\phi: \mathbb{R}^3  \to \mathbb{R}, &\phi (x,y,z)  & \mapsto 4x-5y-2z \\
		\phi: \mathbb{F}^n  \to \mathbb{F}, &\phi (x_1, \dots, x_n)
		& \mapsto c_1x_1 + \dots + c_nx_n  \\
		\phi: \mathcal{P} (\mathbb{R})  \to \mathbb{R},
		& \phi(p) & \mapsto 3p''(5) + 7p(4) \\
		\phi: \mathcal{P}(\mathbb{R}) \to \mathbb{R}, 
		& \phi(p)  &\mapsto \textstyle \int_{0}^{1} p(x) dx
	\end{array}
\end{equation}
\textbf{3.110}
the dual space of $V$, denoted by $V^{*}$, is the vector space of all linear functionals on $V$.
$$V^{*} :\equiv \mathcal{L}(V, \mathbb {F})$$

\textbf{3.111} $\dim V^{*} = \dim V$. \textbf{Proof:} $\dim V^{*} = \dim \mathcal{L}(V, \mathbb{F})=(\dim V) \cdot (\dim \mathbb{F}) = \dim V $

\textbf{3.112} Dual basis: If $V=\myspan {\onetillm{v}}$, then $V^{*} :\equiv 	
\myspan{\varphi_1, \dots, \varphi_m}$ such that
$\varphi_j(v_k) :\equiv
\begin{cases}
	1,  & \text{if $k=j$} \\
	0, & \text{if $k \neq j$}
\end{cases}$

\textbf{3.114} $\onetillm{\varphi}$ is called a dual basis of $\onetillm{v}$ because for $v \in V$ we have $v=\varphi_1 (v)v_1 + \cdots \varphi_m(v)v_m = c_1v_1 + \cdots c_mv_m$ $\iff$ $\varphi(v)=\phi(c_1v_1 + \cdots + c_mv_m)$ such that $\varphi_j(v)=c_j$, because $\varphi$ is linear and $\varphi_j(v_j)=1$ by definition.

\textbf{3.116} The dual basis of a basis of $V$ is a basis of the dual space $V^{*}$

\textbf{3.118} Suppose $T \in \lvw$. The dual map of $T$ is the linear map $T^{*} \in \lin{W^{*}}{V^{*}}$ defined like this:
\begin{align}
	&\forall \phi \in W^{*}: T^{*}(\varphi) :\equiv \varphi \circ T \\
	(&\varphi \in W^{*}=\lin{W}{\mathbb{F}} \text{ and } T^{*}(\varphi) \in V^{*} = \lin{V}{\mathbb{F}} \\
	&\text{So $T^{*}$ is indeed a map from $W^{*}$ to $V^{*}$} 
\end{align}

\begin{itemize}
	\item $\varphi, \psi \in W^{*} \implies T^{*} (\varphi + \psi) = (\varphi + \psi) \circ T = \varphi \circ T + \psi \circ T = T^{*} (\varphi) + T^{*} (\psi)$
	\item $\lambda \in \mathbb{F}, \varphi \in W \implies T^{*} (\lambda \varphi) = (\lambda \varphi) \circ T = \lambda (\varphi \circ T) = \lambda T^{*} (\varphi)$ 
\end{itemize}


